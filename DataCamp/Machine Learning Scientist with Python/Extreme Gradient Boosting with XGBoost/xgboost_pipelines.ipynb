{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost_pipelines.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kaMDlSUTjxX",
        "colab_type": "text"
      },
      "source": [
        "# Using XGBoost in pipelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaJ_JSo7UihV",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpfvUBIwUmdw",
        "colab_type": "text"
      },
      "source": [
        "D. The LotFrontage column has no missing values and its entries are of type float64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L2_9xyhU55v",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical columns I: LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlpbZmNU8ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Fill missing values with 0\n",
        "df.LotFrontage = df['LotFrontage'].fillna(0)\n",
        "\n",
        "# Create a boolean mask for categorical columns\n",
        "categorical_mask = (df.dtypes == 'object')\n",
        "\n",
        "# Get list of categorical column names\n",
        "categorical_columns = df.columns[categorical_mask].tolist()\n",
        "\n",
        "# Print the head of the categorical columns\n",
        "print(df[categorical_columns].head())\n",
        "\n",
        "# Create LabelEncoder object: le\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Apply LabelEncoder to categorical columns\n",
        "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
        "\n",
        "# Print the head of the LabelEncoded categorical columns\n",
        "print(df[categorical_columns].head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccxiyx0DVocS",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical columns II: OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtKQkqzuVoyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create OneHotEncoder: ohe\n",
        "ohe = OneHotEncoder(categorical_features=categorical_mask, sparse=False)\n",
        "\n",
        "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
        "df_encoded = ohe.fit_transform(df)\n",
        "\n",
        "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
        "print(df_encoded[:5, :])\n",
        "\n",
        "# Print the shape of the original DataFrame\n",
        "print(df.shape)\n",
        "\n",
        "# Print the shape of the transformed array\n",
        "print(df_encoded.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mthTmbfkWRVW",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical columns III: DictVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4n6GMVFWRse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import DictVectorizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# Convert df into a dictionary: df_dict\n",
        "df_dict = df.to_dict('records')\n",
        "\n",
        "# Create the DictVectorizer object: dv\n",
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "# Apply dv on df: df_encoded\n",
        "df_encoded = dv.fit_transform(df_dict)\n",
        "\n",
        "# Print the resulting first five rows\n",
        "print(df_encoded[:5,:])\n",
        "\n",
        "# Print the vocabulary\n",
        "print(dv.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pmM1p1-XIuR",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing within a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlC4NgY9XJDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Fill LotFrontage missing values with 0\n",
        "X.LotFrontage = X['LotFrontage'].fillna(0)\n",
        "\n",
        "# Setup the pipeline steps: steps\n",
        "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
        "         (\"xgb_model\", xgb.XGBRegressor())]\n",
        "\n",
        "# Create the pipeline: xgb_pipeline\n",
        "xgb_pipeline = Pipeline(steps)\n",
        "\n",
        "# Fit the pipeline\n",
        "xgb_pipeline.fit(X.to_dict('records'), y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtuAlLayYih_",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validating your XGBoost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq9QvNeVYi34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Fill LotFrontage missing values with 0\n",
        "X.LotFrontage = X.LotFrontage.fillna(0)\n",
        "\n",
        "# Setup the pipeline steps: steps\n",
        "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
        "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\n",
        "\n",
        "# Create the pipeline: xgb_pipeline\n",
        "xgb_pipeline = Pipeline(steps)\n",
        "\n",
        "# Cross-validate the model\n",
        "cross_val_scores = cross_val_score(xgb_pipeline, X.to_dict('record'), y, cv=10, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Print the 10-fold RMSE\n",
        "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqfLIZ-jZDAY",
        "colab_type": "text"
      },
      "source": [
        "## Kidney disease case study I: Categorical Imputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "532Z5TX7ZDV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn_pandas import CategoricalImputer\n",
        "\n",
        "# Check number of nulls in each feature column\n",
        "nulls_per_column = X.isnull().sum()\n",
        "print(nulls_per_column)\n",
        "\n",
        "# Create a boolean mask for categorical columns\n",
        "categorical_feature_mask = X.dtypes == object\n",
        "\n",
        "# Get list of categorical column names\n",
        "categorical_columns = X.columns[categorical_feature_mask].tolist()\n",
        "\n",
        "# Get list of non-categorical column names\n",
        "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n",
        "\n",
        "# Apply numeric imputer\n",
        "numeric_imputation_mapper = DataFrameMapper(\n",
        "                                            [([numeric_feature],Imputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n",
        "                                            input_df=True,\n",
        "                                            df_out=True\n",
        "                                           )\n",
        "\n",
        "# Apply categorical imputer\n",
        "categorical_imputation_mapper = DataFrameMapper(\n",
        "                                                [(category_feature, CategoricalImputer()) for category_feature in categorical_columns],\n",
        "                                                input_df=True,\n",
        "                                                df_out=True\n",
        "                                               )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXXipohYagOv",
        "colab_type": "text"
      },
      "source": [
        "## Kidney disease case study II: Feature Union"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SchOP7dnagl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import FeatureUnion\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "# Combine the numeric and categorical transformations\n",
        "numeric_categorical_union = FeatureUnion([\n",
        "                                          (\"num_mapper\", numeric_imputation_mapper),\n",
        "                                          (\"cat_mapper\", categorical_imputation_mapper)\n",
        "                                         ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAk0_sYwa13p",
        "colab_type": "text"
      },
      "source": [
        "## Kidney disease case study III: Full pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LC7Bfoaa2PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create full pipeline\n",
        "pipeline = Pipeline([\n",
        "                     (\"featureunion\", numeric_categorical_union),\n",
        "                     (\"dictifier\", Dictifier()),\n",
        "                     (\"vectorizer\", DictVectorizer(sort=False)),\n",
        "                     (\"clf\", xgb.XGBClassifier(max_depth=3))\n",
        "                    ])\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val_scores = cross_val_score(pipeline, X, y, scoring=\"roc_auc\", cv=3)\n",
        "\n",
        "# Print avg. AUC\n",
        "print(\"3-fold AUC: \", np.mean(cross_val_scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNEJ68y8cHHv",
        "colab_type": "text"
      },
      "source": [
        "## Bringing it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU_yHfE-cHeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the parameter grid\n",
        "gbm_param_grid = {\n",
        "    'clf__learning_rate': np.arange(0.05, 1.0, 0.05),\n",
        "    'clf__max_depth': np.arange(3, 10, 1),\n",
        "    'clf__n_estimators': np.arange(50, 200, 50)\n",
        "}\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "randomized_roc_auc = RandomizedSearchCV(pipeline, param_distributions=gbm_param_grid, n_iter=2, verbose=1, scoring='roc_auc', cv=2)\n",
        "\n",
        "# Fit the estimator\n",
        "randomized_roc_auc.fit(X, y)\n",
        "\n",
        "# Compute metrics\n",
        "print(randomized_roc_auc.best_score_)\n",
        "print(randomized_roc_auc.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}