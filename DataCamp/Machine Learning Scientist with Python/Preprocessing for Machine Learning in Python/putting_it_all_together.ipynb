{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "putting_it_all_together.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-GT7X4EY9tD",
        "colab_type": "text"
      },
      "source": [
        "# Putting it all together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boMW7YhAYuUl",
        "colab_type": "text"
      },
      "source": [
        "## Checking column types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQoRPAwfY61f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the column types\n",
        "print(ufo.dtypes)\n",
        "\n",
        "# Change the type of seconds to float\n",
        "ufo[\"seconds\"] = ufo['seconds'].astype('float')\n",
        "\n",
        "# Change the date column to type datetime\n",
        "ufo[\"date\"] = pd.to_datetime(ufo['date'])\n",
        "\n",
        "# Check the column types\n",
        "print(ufo[['seconds', 'date']].dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM12L78QZS3D",
        "colab_type": "text"
      },
      "source": [
        "## Dropping missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOPi_dfZTOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check how many values are missing in the length_of_time, state, and type columns\n",
        "print(ufo[['length_of_time', 'state', 'type']].isnull().sum())\n",
        "\n",
        "# Keep only rows where length_of_time, state, and type are not null\n",
        "ufo_no_missing = ufo[ufo['length_of_time'].notnull() & \n",
        "          ufo['state'].notnull() & \n",
        "          ufo['type'].notnull()]\n",
        "\n",
        "# Print out the shape of the new dataset\n",
        "print(ufo_no_missing.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlmUcS3FZ6uD",
        "colab_type": "text"
      },
      "source": [
        "## Extracting numbers from strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9azcPVaZ7EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_minutes(time_string):\n",
        "\n",
        "    # Use \\d+ to grab digits\n",
        "    pattern = re.compile(r\"\\d+\")\n",
        "    \n",
        "    # Use match on the pattern and column\n",
        "    num = re.match(pattern, time_string)\n",
        "    if num is not None:\n",
        "        return int(num.group(0))\n",
        "        \n",
        "# Apply the extraction to the length_of_time column\n",
        "ufo[\"minutes\"] = ufo[\"length_of_time\"].apply(return_minutes)\n",
        "\n",
        "# Take a look at the head of both of the columns\n",
        "print(ufo[['minutes', 'length_of_time']].head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyZ0iCj4aOFJ",
        "colab_type": "text"
      },
      "source": [
        "## Identifying features for standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEhilHrzaOcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the variance of the seconds and minutes columns\n",
        "print(ufo[['seconds', 'minutes']].var())\n",
        "\n",
        "# Log normalize the seconds column\n",
        "ufo[\"seconds_log\"] = np.log(ufo['seconds'])\n",
        "\n",
        "# Print out the variance of just the seconds_log column\n",
        "print(ufo['seconds_log'].var())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaX5weL9auXY",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym3MSWosauva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Pandas to encode us values as 1 and others as 0\n",
        "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda x: 1 if x == 'us' else 0)\n",
        "\n",
        "# Print the number of unique type values\n",
        "print(len(ufo['type'].unique()))\n",
        "\n",
        "# Create a one-hot encoded set of the type values\n",
        "type_set = pd.get_dummies(ufo['type'])\n",
        "\n",
        "# Concatenate this set back to the ufo DataFrame\n",
        "ufo = pd.concat([ufo, type_set], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jInFtryZbSW0",
        "colab_type": "text"
      },
      "source": [
        "## Features from dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhssxxyZbSud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at the first 5 rows of the date column\n",
        "print(ufo['date'].head())\n",
        "\n",
        "# Extract the month from the date column\n",
        "ufo[\"month\"] = ufo[\"date\"].dt.month\n",
        "\n",
        "# Extract the year from the date column\n",
        "ufo[\"year\"] = ufo[\"date\"].dt.year\n",
        "\n",
        "# Take a look at the head of all three columns\n",
        "print(ufo[['date', 'month', 'year']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njt3YeGKbgFa",
        "colab_type": "text"
      },
      "source": [
        "## Text vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPMj92F_bgdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take a look at the head of the desc field\n",
        "print(ufo['desc'].head())\n",
        "\n",
        "# Create the tfidf vectorizer object\n",
        "vec = TfidfVectorizer()\n",
        "\n",
        "# Use vec's fit_transform method on the desc field\n",
        "desc_tfidf = vec.fit_transform(ufo['desc'])\n",
        "\n",
        "# Look at the number of columns this creates\n",
        "print(desc_tfidf.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE8znAiRb8nt",
        "colab_type": "text"
      },
      "source": [
        "## Selecting the ideal dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQm-EPftb8-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
        "print(ufo[[\"seconds\", \"seconds_log\", \"minutes\"]].corr())\n",
        "\n",
        "# Make a list of features to drop   \n",
        "to_drop = [\"city\", \"country\", \"date\", \"desc\", \"lat\", \"length_of_time\", \"long\", \"minutes\", \"recorded\", \"seconds\", \"state\"]\n",
        "\n",
        "# Drop those features\n",
        "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
        "\n",
        "# Let's also filter some words out of the text vector we created\n",
        "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_3UktXPcpQP",
        "colab_type": "text"
      },
      "source": [
        "## Modeling the UFO dataset, part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cINCalcfcpn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take a look at the features in the X set of data\n",
        "print(X.columns)\n",
        "\n",
        "# Split the X and y sets using train_test_split, setting stratify=y\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y)\n",
        "\n",
        "# Fit knn to the training sets\n",
        "knn.fit(train_X, train_y)\n",
        "\n",
        "# Print the score of knn on the test sets\n",
        "print(knn.score(test_X, test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6zAVpBuc7i8",
        "colab_type": "text"
      },
      "source": [
        "## Modeling the UFO dataset, part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i9ic3J1c77N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the list of filtered words we created to filter the text vector\n",
        "filtered_text = desc_tfidf[:, list(filtered_words)]\n",
        "\n",
        "# Split the X and y sets using train_test_split, setting stratify=y \n",
        "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
        "\n",
        "# Fit nb to the training sets\n",
        "nb.fit(train_X, train_y)\n",
        "\n",
        "# Print the score of nb on the test sets\n",
        "print(nb.score(test_X, test_y))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}