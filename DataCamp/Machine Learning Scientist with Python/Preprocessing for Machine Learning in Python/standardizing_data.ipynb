{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "standardizing_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhlDPH5d5ULR",
        "colab_type": "text"
      },
      "source": [
        "# Standardizing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi3BrHoSy12J",
        "colab_type": "text"
      },
      "source": [
        "## When to standardize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6iPf2n5T0F",
        "colab_type": "text"
      },
      "source": [
        "D. Your dataset is comprised of categorical data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAnEp_ke5d6p",
        "colab_type": "text"
      },
      "source": [
        "## Modeling without normalizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLj3VgOG5flc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset and labels into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Fit the k-nearest neighbors model to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Score the model on the test data\n",
        "print(knn.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY_tNHTQ6i8y",
        "colab_type": "text"
      },
      "source": [
        "## Checking the variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGxBtcuz6jTQ",
        "colab_type": "text"
      },
      "source": [
        "B. Proline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOkwRDfW6pN-",
        "colab_type": "text"
      },
      "source": [
        "## Log normalization in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq1wl5zB6uqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the variance of the Proline column\n",
        "print(wine['Proline'].var())\n",
        "\n",
        "# Apply the log normalization function to the Proline column\n",
        "wine['Proline_log'] = np.log(wine['Proline'])\n",
        "\n",
        "# Check the variance of the normalized Proline column\n",
        "print(wine['Proline_log'].var())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuyHu_Ts7bH0",
        "colab_type": "text"
      },
      "source": [
        "## Scaling data - investigating columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjPmLEcz7bez",
        "colab_type": "text"
      },
      "source": [
        "D. 1 and 2 are true."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ML_bLES7-lm",
        "colab_type": "text"
      },
      "source": [
        "## Scaling data - standardizing columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA_CnEec8AVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import StandardScaler from scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create the scaler\n",
        "ss = StandardScaler()\n",
        "\n",
        "# Take a subset of the DataFrame you want to scale \n",
        "wine_subset = wine[['Ash', 'Alcalinity of ash', 'Magnesium']]\n",
        "\n",
        "# Apply the scaler to the DataFrame subset\n",
        "wine_subset_scaled = ss.fit_transform(wine_subset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDS5Y4UN8loR",
        "colab_type": "text"
      },
      "source": [
        "## KNN on non-scaled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q53guvhm8l_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset and labels into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Fit the k-nearest neighbors model to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Score the model on the test data\n",
        "print(knn.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzGRtwi78xhQ",
        "colab_type": "text"
      },
      "source": [
        "## KNN on scaled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqVHEip8x4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the scaling method.\n",
        "ss = StandardScaler()\n",
        "\n",
        "# Apply the scaling method to the dataset used for modeling.\n",
        "X_scaled = ss.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
        "\n",
        "# Fit the k-nearest neighbors model to the training data.\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Score the model on the test data.\n",
        "print(knn.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}