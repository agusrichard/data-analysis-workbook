{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gridsearch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue-OCxs-YnF3",
        "colab_type": "text"
      },
      "source": [
        "## Grid search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ_Jk_pQY4Qb",
        "colab_type": "text"
      },
      "source": [
        "## Build Grid Search functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSIE8HJcagRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the function\n",
        "def gbm_grid_search(learn_rate, max_depth):\n",
        "\n",
        "\t# Create the model\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth)\n",
        "    \n",
        "    # Use the model to make predictions\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    \n",
        "    # Return the hyperparameters and score\n",
        "    return([learn_rate, max_depth, accuracy_score(y_test, predictions)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Heoxfsa1Rv",
        "colab_type": "text"
      },
      "source": [
        "## Iteratively tune multiple hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okj4msrOa1os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the relevant lists\n",
        "results_list = []\n",
        "learn_rate_list = [0.01, 0.1, 0.5]\n",
        "max_depth_list = [2, 4, 6]\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        results_list.append(gbm_grid_search(learn_rate, max_depth))\n",
        "\n",
        "# Print the results\n",
        "print(results_list)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPusFxNCbS0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_list = []\n",
        "learn_rate_list = [0.01, 0.1, 0.5]\n",
        "max_depth_list = [2,4,6]\n",
        "\n",
        "# Extend the function input\n",
        "def gbm_grid_search_extended(learn_rate, max_depth, subsample):\n",
        "\n",
        "\t# Extend the model creation section\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, subsample=subsample)\n",
        "    \n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    \n",
        "    # Extend the return part\n",
        "    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGqJ4XYTbalE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_list = []\n",
        "\n",
        "# Create the new list to test\n",
        "subsample_list = [0.4, 0.6]\n",
        "\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "    \n",
        "    \t# Extend the for loop\n",
        "        for subsample in subsample_list:\n",
        "        \t\n",
        "            # Extend the results to include the new hyperparameter\n",
        "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
        "            \n",
        "# Print results\n",
        "print(results_list)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP40Cu3sbc7T",
        "colab_type": "text"
      },
      "source": [
        "## How Many Models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb6wJSJNbdRo",
        "colab_type": "text"
      },
      "source": [
        "D, 1215"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGTNyDgHcDD3",
        "colab_type": "text"
      },
      "source": [
        "## GridSearchCV inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO4iKcRIdGdJ",
        "colab_type": "text"
      },
      "source": [
        "C. would not work when we try to fit it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKziIXFudM2l",
        "colab_type": "text"
      },
      "source": [
        "## GridSearchCV with Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3r_XmdodP15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Random Forest Classifier with specified criterion\n",
        "rf_class = RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "# Create the parameter grid\n",
        "param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']} \n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_rf_class = GridSearchCV(\n",
        "    estimator=rf_class,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=4,\n",
        "    cv=5,\n",
        "    refit=True, return_train_score=True)\n",
        "print(grid_rf_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL19tTEpeco7",
        "colab_type": "text"
      },
      "source": [
        "## Using the best outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FtDnzkIedBE",
        "colab_type": "text"
      },
      "source": [
        "B. refit = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF88scwOehz5",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the grid search results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm4hP_Aiejur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the cv_results property into a dataframe & print it out\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "print(cv_results_df)\n",
        "\n",
        "# Extract and print the column with a dictionary of hyperparameters used\n",
        "column = cv_results_df.loc[:, [\"params\"]]\n",
        "print(column)\n",
        "\n",
        "# Extract and print the row that had the best mean test score\n",
        "best_row = cv_results_df[cv_results_df[\"rank_test_score\"] == 1]\n",
        "print(best_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPILp8je4ez",
        "colab_type": "text"
      },
      "source": [
        "## Analyzing the best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG1lVTmue41Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the ROC_AUC score from the best-performing square\n",
        "best_score = grid_rf_class.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Create a variable from the row related to the best-performing square\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
        "print(best_row)\n",
        "\n",
        "# Get the n_estimators parameter from the best-performing square and print\n",
        "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
        "print(best_n_estimators)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osbwGI4sfgK9",
        "colab_type": "text"
      },
      "source": [
        "## Using the best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8-8w1UfgiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See what type of object the best_estimator_ property is\n",
        "print(type(grid_rf_class.best_estimator_))\n",
        "\n",
        "# Create an array of predictions directly using the best_estimator_ property\n",
        "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
        "\n",
        "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Now create a confusion matrix \n",
        "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Get the ROC-AUC score\n",
        "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}