{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "understanding_improving_dcnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PBVQtVYUIi-",
        "colab_type": "text"
      },
      "source": [
        "# Understanding and Improving Deep Convolutional Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOWHjLdcVGsC",
        "colab_type": "text"
      },
      "source": [
        "## Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QSliMgSVMzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and store the training object\n",
        "training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
        "\n",
        "# Extract the history from the training object\n",
        "history = training.history\n",
        "\n",
        "# Plot the training loss \n",
        "plt.plot(history['loss'])\n",
        "# Plot the validation loss\n",
        "plt.plot(history['val_loss'])\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYk25WgIVbwh",
        "colab_type": "text"
      },
      "source": [
        "## Using stored weights to predict in a test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeT8YtyNVcet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the weights from file\n",
        "model.load_weights('weights.hdf5')\n",
        "\n",
        "# Predict from the first three images in the test data\n",
        "model.predict(test_data[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaCUQvQ5WknY",
        "colab_type": "text"
      },
      "source": [
        "## Adding dropout to your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSiaMPF4Wk-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a convolutional layer\n",
        "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
        "                 input_shape=(img_rows, img_cols, 1)))\n",
        "\n",
        "# Add a dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Add another convolutional layer\n",
        "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
        "\n",
        "# Flatten and feed to output layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhW1XLjOWu81",
        "colab_type": "text"
      },
      "source": [
        "## Add batch normalization to your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7GHqfKeWvUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a convolutional layer\n",
        "model.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
        "\n",
        "\n",
        "# Add batch normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add another convolutional layer\n",
        "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
        "\n",
        "# Flatten and feed to output layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELTynHkeYHUx",
        "colab_type": "text"
      },
      "source": [
        "## Extracting a kernel from a trained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb7x31XMYH5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the weights into the model\n",
        "model.load_weights('weights.hdf5')\n",
        "\n",
        "# Get the first convolutional layer from the model\n",
        "c1 = model.layers[0]\n",
        "\n",
        "# Get the weights of the first convolutional layer\n",
        "weights1 = c1.get_weights()\n",
        "\n",
        "# Pull out the first channel of the first kernel in the first layer\n",
        "kernel = weights1[0][:, :, 0, 0]\n",
        "print(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVVCcPfEY4kx",
        "colab_type": "text"
      },
      "source": [
        "## Shape of the weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkCCl6QqY48o",
        "colab_type": "text"
      },
      "source": [
        "B. The kernel size is 2 by 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Pndf5tZBVE",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing kernel responses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eHIrXapZDak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convolve with the fourth image in test_data\n",
        "out = convolution(test_data[3, :, :, 0], kernel)\n",
        "\n",
        "# Visualize the result\n",
        "plt.imshow(out)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}