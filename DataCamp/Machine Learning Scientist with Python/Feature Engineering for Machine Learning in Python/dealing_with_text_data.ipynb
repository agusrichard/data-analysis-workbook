{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dealing_with_text_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdLUTXD_zRi8",
        "colab_type": "text"
      },
      "source": [
        "## Dealing with Text Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbJMBQoNznJ8",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning up your text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-g30yxj0fjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the first 5 rows of the text column\n",
        "print(speech_df['text'].head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW9c3zpI0yem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace all non letter characters with a whitespace\n",
        "speech_df['text_clean'] = speech_df['text'].str.replace('[^a-zA-Z]', ' ')\n",
        "\n",
        "# Change to lower case\n",
        "speech_df['text_clean'] = speech_df['text_clean'].str.lower()\n",
        "\n",
        "# Print the first 5 rows of the text_clean column\n",
        "print(speech_df['text_clean'].head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Feiv7KzW00fZ",
        "colab_type": "text"
      },
      "source": [
        "## High level text features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_2VFfSH00-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the length of each text\n",
        "speech_df['char_cnt'] = speech_df['text_clean'].str.len()\n",
        "\n",
        "# Count the number of words in each text\n",
        "speech_df['word_cnt'] = speech_df['text_clean'].str.split().str.len()\n",
        "\n",
        "# Find the average length of word\n",
        "speech_df['avg_word_length'] = speech_df['char_cnt'] / speech_df['word_cnt']\n",
        "\n",
        "# Print the first 5 rows of these columns\n",
        "print(speech_df[['text_clean', 'char_cnt', 'word_cnt', 'avg_word_length']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqvlc-bp17ZQ",
        "colab_type": "text"
      },
      "source": [
        "## Counting words (I)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH67NbCF177m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Instantiate CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer\n",
        "cv.fit(speech_df['text_clean'])\n",
        "\n",
        "# Print feature names\n",
        "print(cv.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgUK5G5yiTH6",
        "colab_type": "text"
      },
      "source": [
        "## Counting words (II)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOEdvQhViTg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the vectorizer\n",
        "cv_transformed = cv.transform(speech_df['text_clean'])\n",
        "\n",
        "# Print the full array\n",
        "cv_array = cv_transformed.toarray()\n",
        "print(cv_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLRbx8lQiftO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the vectorizer\n",
        "cv_transformed = cv.transform(speech_df['text_clean'])\n",
        "\n",
        "# Print the full array\n",
        "cv_array = cv_transformed.toarray()\n",
        "\n",
        "# Print the shape of cv_array\n",
        "print(cv_array.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQbtnQ4OiiET",
        "colab_type": "text"
      },
      "source": [
        "## Limiting your features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmeIZQdliidC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Specify arguements to limit the number of features generated\n",
        "cv = CountVectorizer(min_df=0.2, max_df=0.8)\n",
        "\n",
        "# Fit, transform, and convert into array\n",
        "cv_transformed = cv.fit_transform(speech_df['text_clean'])\n",
        "cv_array = cv_transformed.toarray()\n",
        "\n",
        "# Print the array shape\n",
        "print(cv_array.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZudy5WWi2i_",
        "colab_type": "text"
      },
      "source": [
        "## Text to DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng2xkxkei3DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a DataFrame with these features\n",
        "cv_df = pd.DataFrame(cv_array, \n",
        "                     columns=cv.get_feature_names()).add_prefix('Counts_')\n",
        "\n",
        "# Add the new columns to the original DataFrame\n",
        "speech_df_new = pd.concat([speech_df, cv_df], axis=1, sort=False)\n",
        "print(speech_df_new.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXclLTnukLCd",
        "colab_type": "text"
      },
      "source": [
        "## Tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08E_Gn3kkLcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate TfidfVectorizer\n",
        "tv = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "\n",
        "# Fit the vectroizer and transform the data\n",
        "tv_transformed = tv.fit_transform(speech_df['text_clean'])\n",
        "\n",
        "# Create a DataFrame with these features\n",
        "tv_df = pd.DataFrame(tv_transformed.toarray(), \n",
        "                     columns=tv.get_feature_names()).add_prefix('TFIDF_')\n",
        "print(tv_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUPIKYY5krrH",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting Tf-idf values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbTo9luNksD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Isolate the row to be examined\n",
        "sample_row = tv_df.iloc[0]\n",
        "\n",
        "# Print the top 5 words of the sorted output\n",
        "print(sample_row.sort_values(ascending=False).head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpI5kfTrlGWf",
        "colab_type": "text"
      },
      "source": [
        "## Transforming unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggF6buHClGxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate TfidfVectorizer\n",
        "tv = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "\n",
        "# Fit the vectroizer and transform the data\n",
        "tv_transformed = tv.fit_transform(train_speech_df['text_clean'])\n",
        "\n",
        "# Transform test data\n",
        "test_tv_transformed = tv.transform(test_speech_df['text_clean'])\n",
        "\n",
        "# Create new features for the test set\n",
        "test_tv_df = pd.DataFrame(test_tv_transformed.toarray(), \n",
        "                          columns=tv.get_feature_names()).add_prefix('TFIDF_')\n",
        "print(test_tv_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XlUTipemQmE",
        "colab_type": "text"
      },
      "source": [
        "## Using longer n-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY9J0n7tmlMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Instantiate a trigram vectorizer\n",
        "cv_trigram_vec = CountVectorizer(max_features=100, \n",
        "                                 stop_words='english', \n",
        "                                 ngram_range=(3, 3))\n",
        "\n",
        "# Fit and apply trigram vectorizer\n",
        "cv_trigram = cv_trigram_vec.fit_transform(speech_df['text_clean'])\n",
        "\n",
        "# Print the trigram features\n",
        "print(cv_trigram_vec.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8S1j-emQeG",
        "colab_type": "text"
      },
      "source": [
        "## Finding the most common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbN8NQ3ymo-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a DataFrame of the features\n",
        "cv_tri_df = pd.DataFrame(cv_trigram.toarray(), \n",
        "                 columns=cv_trigram_vec.get_feature_names()).add_prefix('Counts_')\n",
        "\n",
        "# Print the top 5 words in the sorted output\n",
        "print(cv_tri_df.sum().sort_values(ascending=False).head())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}