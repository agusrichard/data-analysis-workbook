{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62r5_fozVMSg",
        "colab_type": "text"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xOfqINHUSPO",
        "colab_type": "text"
      },
      "source": [
        "## Manual feature extraction I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NKQjVFQVLt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the price from the quantity sold and revenue\n",
        "sales_df['price'] = sales_df['revenue'] / sales_df['quantity']\n",
        "\n",
        "# Drop the quantity and revenue features\n",
        "reduced_df = sales_df.drop(['quantity', 'revenue'], axis=1)\n",
        "\n",
        "print(reduced_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N2Il2yFVt-H",
        "colab_type": "text"
      },
      "source": [
        "## Manual feature extraction II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QioTVtr1VuUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the mean height\n",
        "height_df['height'] = height_df[['height_1', 'height_2', 'height_3']].mean(axis=1)\n",
        "\n",
        "# Drop the 3 original height features\n",
        "reduced_df = height_df.drop(['height_1', 'height_2', 'height_3'], axis=1)\n",
        "\n",
        "print(reduced_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZGIMV04WI6T",
        "colab_type": "text"
      },
      "source": [
        "## Principal component intuition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv5gpky4WKym",
        "colab_type": "text"
      },
      "source": [
        "A. People with a negative component for the yellow vector have long forearms relative to their upper arms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbd-tkr8WM5P",
        "colab_type": "text"
      },
      "source": [
        "## Calculating Principal Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCl4SHnIXCJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a pairplot to inspect ansur_df\n",
        "sns.pairplot(ansur_df)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2znmIAKXdUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create the scaler and standardize the data\n",
        "scaler = StandardScaler()\n",
        "ansur_std = scaler.fit_transform(ansur_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GITjTTcfXkEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create the scaler and standardize the data\n",
        "scaler = StandardScaler()\n",
        "ansur_std = scaler.fit_transform(ansur_df)\n",
        "\n",
        "# Create the PCA instance and fit and transform the data with pca\n",
        "pca = PCA()\n",
        "pc = pca.fit_transform(ansur_std)\n",
        "\n",
        "# This changes the numpy array output back to a dataframe\n",
        "pc_df = pd.DataFrame(pc, columns=['PC 1', 'PC 2', 'PC 3', 'PC 4'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBEazrRjXqzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create the scaler\n",
        "scaler = StandardScaler()\n",
        "ansur_std = scaler.fit_transform(ansur_df)\n",
        "\n",
        "# Create the PCA instance and fit and transform the data with pca\n",
        "pca = PCA()\n",
        "pc = pca.fit_transform(ansur_std)\n",
        "pc_df = pd.DataFrame(pc, columns=['PC 1', 'PC 2', 'PC 3', 'PC 4'])\n",
        "\n",
        "# Create a pairplot of the principal component dataframe\n",
        "sns.pairplot(pc_df)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yRgDAoiXwHL",
        "colab_type": "text"
      },
      "source": [
        "## PCA on a larger dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6umdx4gXwa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "ansur_std = scaler.fit_transform(ansur_df)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "pca.fit(ansur_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYoM1EMGX-P0",
        "colab_type": "text"
      },
      "source": [
        "## PCA explained variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV_JSgobX-mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the explained variance ratio per component\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lbFb1oJYC4l",
        "colab_type": "text"
      },
      "source": [
        "B. About 3.77%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm1dVIbnYGqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the cumulative sum of the explained variance ratio\n",
        "print(pca.explained_variance_ratio_.cumsum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r43Y0EE7YZjP",
        "colab_type": "text"
      },
      "source": [
        "C. 4 principal components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wyImh0dYbvj",
        "colab_type": "text"
      },
      "source": [
        "## Understanding the components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfCSbtS4ZcXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=2))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LftrssZBZ1Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=2))])\n",
        "\n",
        "# Fit it to the dataset and extract the component vectors\n",
        "pipe.fit(poke_df)\n",
        "vectors = pipe.steps[1][1].components_.round(2)\n",
        "\n",
        "# Print feature effects\n",
        "print('PC 1 effects = ' + str(dict(zip(poke_df.columns, vectors[0]))))\n",
        "print('PC 2 effects = ' + str(dict(zip(poke_df.columns, vectors[1]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gct68PxaSD9",
        "colab_type": "text"
      },
      "source": [
        "B. All features have a similar positive effect. PC 1 can be interpreted as a measure of overall quality (high stats)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx8jvBjRaSAy",
        "colab_type": "text"
      },
      "source": [
        "A. Defense has a strong positive effect on the second component and speed a strong negative one. This component quantifies an agility vs. armor & protection trade-off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGGzQ6jIacvG",
        "colab_type": "text"
      },
      "source": [
        "## PCA for feature exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6v-Pdrpaffg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reducer', PCA(n_components=2))])\n",
        "\n",
        "# Fit the pipeline to poke_df and transform the data\n",
        "pc = pipe.fit_transform(poke_df)\n",
        "\n",
        "print(pc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_IasOnBa4ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reducer', PCA(n_components=2))])\n",
        "\n",
        "# Fit the pipeline to poke_df and transform the data\n",
        "pc = pipe.fit_transform(poke_df)\n",
        "\n",
        "# Add the 2 components to poke_cat_df\n",
        "poke_cat_df['PC 1'] = pc[:, 0]\n",
        "poke_cat_df['PC 2'] = pc[:, 1]\n",
        "\n",
        "print(poke_cat_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1qrCKLVbC2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reducer', PCA(n_components=2))])\n",
        "\n",
        "# Fit the pipeline to poke_df and transform the data\n",
        "pc = pipe.fit_transform(poke_df)\n",
        "\n",
        "# Add the 2 components to poke_cat_df\n",
        "poke_cat_df['PC 1'] = pc[:, 0]\n",
        "poke_cat_df['PC 2'] = pc[:, 1]\n",
        "\n",
        "# Use the Type feature to color the PC 1 vs PC 2 scatterplot\n",
        "sns.scatterplot(data=poke_cat_df, \n",
        "                x='PC 1', y='PC 2', hue='Type')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqsGRZycbI4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('reducer', PCA(n_components=2))])\n",
        "\n",
        "# Fit the pipeline to poke_df and transform the data\n",
        "pc = pipe.fit_transform(poke_df)\n",
        "\n",
        "# Add the 2 components to poke_cat_df\n",
        "poke_cat_df['PC 1'] = pc[:, 0]\n",
        "poke_cat_df['PC 2'] = pc[:, 1]\n",
        "\n",
        "# Use the Legendary feature to color the PC 1 vs PC 2 scatterplot\n",
        "sns.scatterplot(data=poke_cat_df, \n",
        "                x='PC 1', y='PC 2', hue='Legendary')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RM25fOubQ45",
        "colab_type": "text"
      },
      "source": [
        "## PCA in a model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKP82mXObROV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reducer', PCA(n_components=2)),\n",
        "        ('classifier', RandomForestClassifier(random_state=0))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd8JIgRpbfR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reducer', PCA(n_components=2)),\n",
        "        ('classifier', RandomForestClassifier(random_state=0))])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Prints the explained variance ratio\n",
        "print(pipe.steps[1][1].explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtLw7vSNblE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reducer', PCA(n_components=2)),\n",
        "        ('classifier', RandomForestClassifier(random_state=0))])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Prints the explained variance ratio\n",
        "print(pipe.steps[1][1].explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV3nik5sbqUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the pipeline\n",
        "pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('reducer', PCA(n_components=3)),\n",
        "        ('classifier', RandomForestClassifier(random_state=0))])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Score the accuracy on the test set\n",
        "accuracy = pipe.score(X_test, y_test)\n",
        "\n",
        "# Prints the explained variance ratio and accuracy\n",
        "print(pipe.steps[1][1].explained_variance_ratio_)\n",
        "print('{0:.1%} test set accuracy'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rg6RgKZcnvr",
        "colab_type": "text"
      },
      "source": [
        "## Selecting the proportion of variance to keep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl8oISj9coD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipe a scaler to PCA selecting 80% of the variance\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=0.8))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK91XNU-c0o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipe a scaler to PCA selecting 80% of the variance\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=0.8))])\n",
        "\n",
        "# Fit the pipe to the data\n",
        "pipe.fit(ansur_df)\n",
        "\n",
        "print('{} components selected'.format(len(pipe.steps[1][1].components_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKEb5phXc34s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let PCA select 90% of the variance\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=0.9))])\n",
        "\n",
        "# Fit the pipe to the data\n",
        "pipe.fit(ansur_df)\n",
        "\n",
        "print('{} components selected'.format(len(pipe.steps[1][1].components_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB6uwiE6c85h",
        "colab_type": "text"
      },
      "source": [
        "B. 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yP3XeSYc-G7",
        "colab_type": "text"
      },
      "source": [
        "## Choosing the number of components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FherkR11dAdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipeline a scaler and PCA selecting 10 components\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=10))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiBDc8qrdLb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipeline a scaler and pca selecting 10 components\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=10))])\n",
        "\n",
        "# Fit the pipe to the data\n",
        "pipe.fit(ansur_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anL__GasdQoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipeline a scaler and pca selecting 10 components\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "        \t\t ('reducer', PCA(n_components=10))])\n",
        "\n",
        "# Fit the pipe to the data\n",
        "pipe.fit(ansur_df)\n",
        "\n",
        "# Plot the explained variance ratio\n",
        "plt.plot(pipe.steps[1][1].explained_variance_ratio_)\n",
        "\n",
        "plt.xlabel('Principal component index')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fazUroJCdWrL",
        "colab_type": "text"
      },
      "source": [
        "C. 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KigY5TIodY4E",
        "colab_type": "text"
      },
      "source": [
        "## PCA for image compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2r5zDOOdeFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the MNIST sample data\n",
        "plot_digits(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K1rm1B4duCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the input data to principal components\n",
        "pc = pipe.transform(X_test)\n",
        "\n",
        "# Prints the number of features per dataset\n",
        "print(\"X_test has {} features\".format(X_test.shape[1]))\n",
        "print(\"pc has {} features\".format(pc.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Haq89Q4vd0iC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the input data to principal components\n",
        "pc = pipe.transform(X_test)\n",
        "\n",
        "# Inverse transform the components to original feature space\n",
        "X_rebuilt = pipe.inverse_transform(pc)\n",
        "\n",
        "# Prints the number of features\n",
        "print(\"X_rebuilt has {} features\".format(X_rebuilt.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fun8-unOd56S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the input data to principal components\n",
        "pc = pipe.transform(X_test)\n",
        "\n",
        "# Inverse transform the components to original feature space\n",
        "X_rebuilt = pipe.inverse_transform(pc)\n",
        "\n",
        "# Plot the reconstructed data\n",
        "plot_digits(X_rebuilt)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}