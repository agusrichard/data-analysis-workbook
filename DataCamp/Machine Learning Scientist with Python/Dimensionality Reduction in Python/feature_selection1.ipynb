{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_selection1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8QfOnH8vIPF",
        "colab_type": "text"
      },
      "source": [
        "# Feature selection I, selecting for feature information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K3QoRiHw2aX",
        "colab_type": "text"
      },
      "source": [
        "## Train - test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03IBwlhaw6aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import train_test_split()\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Select the Gender column as the feature to be predicted (y)\n",
        "y = ansur_df['Gender']\n",
        "\n",
        "# Remove the Gender column to create the training data\n",
        "X = ansur_df.drop('Gender', axis=1)\n",
        "\n",
        "# Perform a 70% train and 30% test data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "print(\"{} rows in test set vs. {} in training set. {} Features.\".format(X_test.shape[0], X_train.shape[0], X_test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rHpiSO0xSob",
        "colab_type": "text"
      },
      "source": [
        "## Fitting and testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxYJprrxS_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import SVC from sklearn.svm and accuracy_score from sklearn.metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create an instance of the Support Vector Classification class\n",
        "svc = SVC()\n",
        "\n",
        "# Fit the model to the training data\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Calculate accuracy scores on both train and test data\n",
        "accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n",
        "accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n",
        "\n",
        "print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd367Iu1xsxg",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy after dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cz-56GYxtJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign just the 'neckcircumferencebase' column from ansur_df to X\n",
        "X = ansur_df[['neckcircumferencebase']]\n",
        "\n",
        "# Split the data, instantiate a classifier and fit the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Calculate accuracy scores on both train and test data\n",
        "accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n",
        "accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n",
        "\n",
        "print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxhOnAtG0BNY",
        "colab_type": "text"
      },
      "source": [
        "## Finding a good variance threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQtYfuGV0Bsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the boxplot\n",
        "head_df.boxplot()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tP_qrfN0Phq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data\n",
        "normalized_df = head_df / head_df.mean()\n",
        "\n",
        "normalized_df.boxplot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k7B0W-Y0qJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data\n",
        "normalized_df = head_df / head_df.mean()\n",
        "\n",
        "# Print the variances of the normalized data\n",
        "print((normalized_df.std()) ** 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBlVkTry1cy9",
        "colab_type": "text"
      },
      "source": [
        "## Features with low variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKVxSB5I1dLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Create a VarianceThreshold feature selector\n",
        "sel = VarianceThreshold(threshold=0.001)\n",
        "\n",
        "# Fit the selector to normalized head_df\n",
        "sel.fit(head_df / head_df.mean())\n",
        "\n",
        "# Create a boolean mask\n",
        "mask = sel.get_support()\n",
        "\n",
        "# Apply the mask to create a reduced dataframe\n",
        "reduced_df = head_df.loc[:, mask]\n",
        "\n",
        "print(\"Dimensionality reduced from {} to {}.\".format(head_df.shape[1], reduced_df.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K2_OdOD1p2I",
        "colab_type": "text"
      },
      "source": [
        "## Removing features with many missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPwGTDVT1qMg",
        "colab_type": "text"
      },
      "source": [
        "A. Between 0.9 and 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrHj8prO13v-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a boolean mask on whether each feature less than 50% missing values.\n",
        "mask = school_df.isna().sum() / len(school_df) < 0.5\n",
        "\n",
        "# Create a reduced dataset by applying the mask\n",
        "reduced_df = school_df.loc[:, mask]\n",
        "\n",
        "print(school_df.shape)\n",
        "print(reduced_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "954V7vW53Lzx",
        "colab_type": "text"
      },
      "source": [
        "## Correlation intuition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydhHd_am3ML8",
        "colab_type": "text"
      },
      "source": [
        "A. The correlation coefficient of A to B is equal to that of B to A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AithZhvp3Sg5",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting the correlation matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfp7asXf3UXx",
        "colab_type": "text"
      },
      "source": [
        "A. 0.702178"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uec4LtNm3fV5",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing the correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbPscPEH3hlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the correlation matrix\n",
        "corr = ansur_df.corr()\n",
        "\n",
        "# Draw the heatmap\n",
        "sns.heatmap(corr,  cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg8uoBb23wNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the correlation matrix\n",
        "corr = ansur_df.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86mQwYMn37-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the correlation matrix\n",
        "corr = ansur_df.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle \n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Add the mask to the heatmap\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wjSuP0A4Df7",
        "colab_type": "text"
      },
      "source": [
        "D. Buttock height and Crotch height."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3XF2VI44D8y",
        "colab_type": "text"
      },
      "source": [
        "## Filtering out highly correlated features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cLLprbP4_bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the correlation matrix and take the absolute value\n",
        "corr_matrix = ansur_df.corr().abs()\n",
        "\n",
        "# Create a True/False mask and apply it\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "tri_df = corr_matrix.mask(mask)\n",
        "\n",
        "# List column names of highly correlated features (r > 0.95)\n",
        "to_drop = [c for c in tri_df.columns if any(tri_df[c] >  0.95)]\n",
        "\n",
        "# Drop the features in the to_drop list\n",
        "reduced_df = ansur_df.drop(to_drop, axis=1)\n",
        "\n",
        "print(\"The reduced dataframe has {} columns.\".format(reduced_df.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tMVRvmu5oqb",
        "colab_type": "text"
      },
      "source": [
        "## Nuclear energy and pool drownings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm_S5-kb5pDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the first five lines of weird_df\n",
        "print(weird_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBVulH_f54VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put nuclear energy production on the x-axis and the number of pool drownings on the y-axis\n",
        "sns.scatterplot(x='nuclear_energy', y='pool_drownings', data=weird_df)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DshJgcGh57ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put nuclear energy production on the x-axis and the number of pool drownings on the y-axis\n",
        "sns.scatterplot(x='nuclear_energy', y='pool_drownings', data=weird_df)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCP4SUrt6AVm",
        "colab_type": "text"
      },
      "source": [
        "D. Not much, correlation does not imply causation."
      ]
    }
  ]
}