{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6r3AMx8y2jX",
        "colab_type": "text"
      },
      "source": [
        "# Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDcxFsAd0HvB",
        "colab_type": "text"
      },
      "source": [
        "## Replicate validation score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxScwtdM0Lhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Calculate the mean fare_amount on the validation_train data\n",
        "naive_prediction = np.mean(validation_train['fare_amount'])\n",
        "\n",
        "# Assign naive prediction to all the holdout observations\n",
        "validation_test['pred'] = naive_prediction\n",
        "\n",
        "# Measure the local RMSE\n",
        "rmse = sqrt(mean_squared_error(validation_test['fare_amount'], validation_test['pred']))\n",
        "print('Validation RMSE for Baseline I model: {:.3f}'.format(rmse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_QTlT0s0VOb",
        "colab_type": "text"
      },
      "source": [
        "## Baseline based on the date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvr9uKO00VnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get pickup hour from the pickup_datetime column\n",
        "train['hour'] = train['pickup_datetime'].dt.hour\n",
        "test['hour'] = test['pickup_datetime'].dt.hour\n",
        "\n",
        "# Calculate average fare_amount grouped by pickup hour \n",
        "hour_groups = train.groupby('hour')['fare_amount'].mean()\n",
        "\n",
        "# Make predictions on the test set\n",
        "test['fare_amount'] = test.hour.map(hour_groups)\n",
        "\n",
        "# Write predictions\n",
        "test[['id','fare_amount']].to_csv('hour_mean_sub.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP2cIjtx0mKa",
        "colab_type": "text"
      },
      "source": [
        "## Baseline based on the gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pnp5Jhe0mg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Select only numeric features\n",
        "features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
        "            'dropoff_latitude', 'passenger_count', 'hour']\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(train[features], train.fare_amount)\n",
        "\n",
        "# Make predictions on the test data\n",
        "test['fare_amount'] = rf.predict(test[features])\n",
        "\n",
        "# Write predictions\n",
        "test[['id','fare_amount']].to_csv('rf_sub.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPOX_kw01_Nt",
        "colab_type": "text"
      },
      "source": [
        "## Grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdzz9ryC1_kA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Possible max depth values\n",
        "max_depth_grid = [3, 6, 9, 12, 15]\n",
        "results = {}\n",
        "\n",
        "# For each value in the grid\n",
        "for max_depth_candidate in max_depth_grid:\n",
        "    # Specify parameters for the model\n",
        "    params = {'max_depth': max_depth_candidate}\n",
        "\n",
        "    # Calculate validation score for a particular hyperparameter\n",
        "    validation_score = get_cv_score(train, params)\n",
        "\n",
        "    # Save the results for each max depth value\n",
        "    results[max_depth_candidate] = validation_score   \n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d7gUZHB2KYv",
        "colab_type": "text"
      },
      "source": [
        "## 2D grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91iT0bC22LTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "# Hyperparameter grids\n",
        "max_depth_grid = [3, 5, 7]\n",
        "subsample_grid = [0.8, 0.9, 1]\n",
        "results = {}\n",
        "\n",
        "# For each couple in the grid\n",
        "for max_depth_candidate, subsample_candidate in itertools.product(max_depth_grid, subsample_grid):\n",
        "    params = {'max_depth': max_depth_candidate,\n",
        "              'subsample': subsample_candidate}\n",
        "    validation_score = get_cv_score(train, params)\n",
        "    # Save the results for each couple\n",
        "    results[(max_depth_candidate, subsample_candidate)] = validation_score   \n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlROW1fy4Jw4",
        "colab_type": "text"
      },
      "source": [
        "## Model blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD4Acy214MzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Train a Gradient Boosting model\n",
        "gb = GradientBoostingRegressor().fit(train[features], train.fare_amount)\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf = RandomForestRegressor().fit(train[features], train.fare_amount)\n",
        "\n",
        "# Make predictions on the test data\n",
        "test['gb_pred'] = gb.predict(test[features])\n",
        "test['rf_pred'] = rf.predict(test[features])\n",
        "\n",
        "# Find mean of model predictions\n",
        "test['blend'] = (test['gb_pred'] + test['rf_pred']) / 2\n",
        "print(test[['gb_pred', 'rf_pred', 'blend']].head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPMKSwKc4idK",
        "colab_type": "text"
      },
      "source": [
        "## Model stacking I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYYfPLCo4iy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "# Split train data into two parts\n",
        "part_1, part_2 = train_test_split(train, test_size=0.5, random_state=123)\n",
        "\n",
        "# Train a Gradient Boosting model on Part 1\n",
        "gb = GradientBoostingRegressor().fit(part_1[features], part_1.fare_amount)\n",
        "\n",
        "# Train a Random Forest model on Part 1\n",
        "rf = RandomForestRegressor().fit(part_1[features], part_1.fare_amount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDc2Ab_Q5A0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions on the Part 2 data\n",
        "part_2['gb_pred'] = gb.predict(part_2[features])\n",
        "part_2['rf_pred'] = rf.predict(part_2[features])\n",
        "\n",
        "# Make predictions on the test data\n",
        "test['gb_pred'] = gb.predict(test[features])\n",
        "test['rf_pred'] = rf.predict(test[features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OETHmFJP5DhI",
        "colab_type": "text"
      },
      "source": [
        "## Model stacking II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA2TXfU55D4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create linear regression model without the intercept\n",
        "lr = LinearRegression(fit_intercept=False)\n",
        "\n",
        "# Train 2nd level model on the Part 2 data\n",
        "lr.fit(part_2[['gb_pred', 'rf_pred']], part_2.fare_amount)\n",
        "\n",
        "# Make stacking predictions on the test data\n",
        "test['stacking'] = lr.predict(test[['gb_pred', 'rf_pred']])\n",
        "\n",
        "# Look at the model coefficients\n",
        "print(lr.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R94tBMJH6fKM",
        "colab_type": "text"
      },
      "source": [
        "## Testing Kaggle forum ideas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g3F7m9S6fgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop passenger_count column\n",
        "new_train_1 = train.drop('passenger_count', axis=1)\n",
        "\n",
        "# Compare validation scores\n",
        "initial_score = get_cv_score(train)\n",
        "new_score = get_cv_score(new_train_1)\n",
        "\n",
        "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C99Z9JOg6tWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create copy of the initial train DataFrame\n",
        "new_train_2 = train.copy()\n",
        "\n",
        "# Find sum of pickup latitude and ride distance\n",
        "new_train_2['weird_feature'] = new_train_2['pickup_latitude'] + new_train_2['distance_km']\n",
        "\n",
        "# Compare validation scores\n",
        "initial_score = get_cv_score(train)\n",
        "new_score = get_cv_score(new_train_2)\n",
        "\n",
        "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrlf-BL66yMU",
        "colab_type": "text"
      },
      "source": [
        "## Select final submissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC_0sxKZ6yjN",
        "colab_type": "text"
      },
      "source": [
        "C. 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj8unRVr69ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}