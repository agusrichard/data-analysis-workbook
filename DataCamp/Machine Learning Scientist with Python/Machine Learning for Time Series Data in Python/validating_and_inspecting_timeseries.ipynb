{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "validating_and_inspecting_timeseries.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPdTqbc-_Sz4",
        "colab_type": "text"
      },
      "source": [
        "# Validating and Inspecting Time Series Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14csmto0A0VX",
        "colab_type": "text"
      },
      "source": [
        "## Creating time-shifted features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieAjn5sDCaZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are the \"time lags\"\n",
        "shifts = np.arange(1, 11).astype(int)\n",
        "\n",
        "# Use a dictionary comprehension to create name: value pairs, one pair per shift\n",
        "shifted_data = {\"lag_{}_day\".format(day_shift): prices_perc.shift(day_shift) for day_shift in shifts}\n",
        "\n",
        "# Convert into a DataFrame for subsequent use\n",
        "prices_perc_shifted = pd.DataFrame(shifted_data)\n",
        "\n",
        "# Plot the first 100 samples of each\n",
        "ax = prices_perc_shifted.iloc[:100].plot(cmap=plt.cm.viridis)\n",
        "prices_perc.iloc[:100].plot(color='r', lw=2)\n",
        "ax.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwWgycUTC3X5",
        "colab_type": "text"
      },
      "source": [
        "## Special case: Auto-regressive models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WQ7Q0JaC3wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace missing values with the median for each column\n",
        "X = prices_perc_shifted.fillna(np.nanmedian(prices_perc_shifted))\n",
        "y = prices_perc.fillna(np.nanmedian(prices_perc))\n",
        "\n",
        "# Fit the model\n",
        "model = Ridge()\n",
        "model.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en0naPrPDV1d",
        "colab_type": "text"
      },
      "source": [
        "## Visualize regression coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8vLlSVjDWLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_coefficients(coefs, names, ax):\n",
        "    # Make a bar plot for the coefficients, including their names on the x-axis\n",
        "    ax.bar(names, coefs)\n",
        "    ax.set(xlabel='Coefficient name', ylabel='Coefficient value')\n",
        "    \n",
        "    # Set formatting so it looks nice\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeFspfw0DrCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the output data up to \"2011-01\"\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
        "y.loc[:'2011-01'].plot(ax=axs[0])\n",
        "\n",
        "# Run the function to visualize model's coefficients\n",
        "visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax=axs[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcAF-3g0D13k",
        "colab_type": "text"
      },
      "source": [
        "## Auto-regression with a smoother time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdDQRRMlD2QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the output data up to \"2011-01\"\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
        "y.loc[:'2011-01'].plot(ax=axs[0])\n",
        "\n",
        "# Run the function to visualize model's coefficients\n",
        "visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax=axs[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfzhdYfzGx5y",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation with shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsPY5uYgGyTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import ShuffleSplit and create the cross-validation object\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "cv = ShuffleSplit(n_splits=10, random_state=1)\n",
        "\n",
        "# Iterate through CV splits\n",
        "results = []\n",
        "for tr, tt in cv.split(X, y):\n",
        "    # Fit the model on training data\n",
        "    model.fit(X[tr], y[tr])\n",
        "    \n",
        "    # Generate predictions on the test data, score the predictions, and collect\n",
        "    prediction = model.predict(X[tt])\n",
        "    score = r2_score(y[tt], prediction)\n",
        "    results.append((prediction, score, tt))\n",
        "\n",
        "# Custom function to quickly visualize predictions\n",
        "visualize_predictions(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ZNco2PG6Bt",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation without shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bXabR_hG6Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create KFold cross-validation object\n",
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=10, shuffle=False, random_state=1)\n",
        "\n",
        "# Iterate through CV splits\n",
        "results = []\n",
        "for tr, tt in cv.split(X, y):\n",
        "    # Fit the model on training data\n",
        "    model.fit(X[tr], y[tr])\n",
        "    \n",
        "    # Generate predictions on the test data and collect\n",
        "    prediction = model.predict(X[tt])\n",
        "    results.append((prediction, tt))\n",
        "    \n",
        "# Custom function to quickly visualize predictions\n",
        "visualize_predictions(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YE2pmhTHTMm",
        "colab_type": "text"
      },
      "source": [
        "## Time-based cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnH_8ftWHTkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import TimeSeriesSplit\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# Create time-series cross-validation object\n",
        "cv = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# Iterate through CV splits\n",
        "fig, ax = plt.subplots()\n",
        "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
        "    # Plot the training data on each iteration, to see the behavior of the CV\n",
        "    ax.plot(tr, ii + y[tr])\n",
        "\n",
        "ax.set(title='Training data on each CV iteration', ylabel='CV iteration')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF33D47LJF6O",
        "colab_type": "text"
      },
      "source": [
        "## Stationarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFZ1EUFqJGRK",
        "colab_type": "text"
      },
      "source": [
        "D. B and C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFmxQqVMJQzb",
        "colab_type": "text"
      },
      "source": [
        "## Bootstrapping a confidence interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smc5flGFJSuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "def bootstrap_interval(data, percentiles=(2.5, 97.5), n_boots=100):\n",
        "    \"\"\"Bootstrap a confidence interval for the mean of columns of a 2-D dataset.\"\"\"\n",
        "    # Create our empty array to fill the results\n",
        "    bootstrap_means = np.zeros([n_boots, data.shape[-1]])\n",
        "    for ii in range(n_boots):\n",
        "        # Generate random indices for our data *with* replacement, then take the sample mean\n",
        "        random_sample = resample(data)\n",
        "        bootstrap_means[ii] = random_sample.mean(axis=0)\n",
        "        \n",
        "    # Compute the percentiles of choice for the bootstrapped means\n",
        "    percentiles = np.percentile(bootstrap_means, percentiles, axis=0)\n",
        "    return percentiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_h_MtZ9J3wE",
        "colab_type": "text"
      },
      "source": [
        "## Calculating variability in model coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekQR3_1yJ4Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate through CV splits\n",
        "n_splits = 100\n",
        "cv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Create empty array to collect coefficients\n",
        "coefficients = np.empty([n_splits, X.shape[1]])\n",
        "\n",
        "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
        "    # Fit the model on training data and collect the coefficients\n",
        "    model.fit(X[tr], y[tr])\n",
        "    coefficients[ii] = model.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Erf3gtKjGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate a confidence interval around each coefficient\n",
        "bootstrapped_interval = bootstrap_interval(coefficients)\n",
        "\n",
        "# Plot it\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(feature_names, bootstrapped_interval[0], marker='_', lw=3)\n",
        "ax.scatter(feature_names, bootstrapped_interval[1], marker='_', lw=3)\n",
        "ax.set(title='95% confidence interval for model coefficients')\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B06eajm8KouO",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing model score variability over time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQsumk_UKpF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Generate scores for each split to see how the model performs over time\n",
        "scores = cross_val_score(model, X, y, cv=cv, scoring=my_pearsonr)\n",
        "\n",
        "# Convert to a Pandas Series object\n",
        "scores_series = pd.Series(scores, index=times_scores, name='score')\n",
        "\n",
        "# Bootstrap a rolling confidence interval for the mean score\n",
        "scores_lo = scores_series.rolling(20).aggregate(partial(bootstrap_interval, percentiles=2.5))\n",
        "scores_hi = scores_series.rolling(20).aggregate(partial(bootstrap_interval, percentiles=97.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgFxTdjtLIxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "scores_lo.plot(ax=ax, label=\"Lower confidence interval\")\n",
        "scores_hi.plot(ax=ax, label=\"Upper confidence interval\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W9HfZ8dLREk",
        "colab_type": "text"
      },
      "source": [
        "## Accounting for non-stationarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYPnuQvjLRbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-initialize window sizes\n",
        "window_sizes = [25, 50, 75, 100]\n",
        "\n",
        "# Create an empty DataFrame to collect the stores\n",
        "all_scores = pd.DataFrame(index=times_scores)\n",
        "\n",
        "# Generate scores for each split to see how the model performs over time\n",
        "for window in window_sizes:\n",
        "    # Create cross-validation object using a limited lookback window\n",
        "    cv = TimeSeriesSplit(n_splits=100, max_train_size=window)\n",
        "    \n",
        "    # Calculate scores across all CV splits and collect them in a DataFrame\n",
        "    this_scores = cross_val_score(model, X, y, cv=cv, scoring=my_pearsonr)\n",
        "    all_scores['Length {}'.format(window)] = this_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5XpgWGuLpSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the scores\n",
        "ax = all_scores.rolling(10).mean().plot(cmap=plt.cm.coolwarm)\n",
        "ax.set(title='Scores for multiple windows', ylabel='Correlation (r)')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}