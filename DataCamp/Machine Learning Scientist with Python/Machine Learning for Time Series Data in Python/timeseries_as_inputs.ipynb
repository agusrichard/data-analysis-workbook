{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "timeseries_as_inputs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHm9GSe6fnMg",
        "colab_type": "text"
      },
      "source": [
        "# Time Series as Inputs to a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bFZMAR0fp-V",
        "colab_type": "text"
      },
      "source": [
        "## Many repetitions of sounds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USnf_c2lef-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)\n",
        "\n",
        "# Calculate the time array\n",
        "time = np.arange(normal.shape[0]) / sfreq\n",
        "\n",
        "# Stack the normal/abnormal audio so you can loop and plot\n",
        "stacked_audio = np.hstack([normal, abnormal]).T\n",
        "\n",
        "# Loop through each audio file / ax object and plot\n",
        "# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping\n",
        "for iaudio, ax in zip(stacked_audio, axs.T.ravel()):\n",
        "    ax.plot(time, iaudio)\n",
        "show_plot_and_make_titles()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mdScBjZf5WC",
        "colab_type": "text"
      },
      "source": [
        "## Invariance in time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lVzMelvf5ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average across the audio files of each DataFrame\n",
        "mean_normal = np.mean(normal, axis=1)\n",
        "mean_abnormal = np.mean(abnormal, axis=1)\n",
        "\n",
        "# Plot each average over time\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
        "ax1.plot(time, mean_normal)\n",
        "ax1.set(title=\"Normal Data\")\n",
        "ax2.plot(time, mean_abnormal)\n",
        "ax2.set(title=\"Abnormal Data\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9oBsPrGgb0Z",
        "colab_type": "text"
      },
      "source": [
        "## Build a classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BzG2Tqngcqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Initialize and fit the model\n",
        "model = LinearSVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions and score them manually\n",
        "predictions = model.predict(X_test)\n",
        "print(sum(predictions == y_test.squeeze()) / len(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BU28Awah4wE",
        "colab_type": "text"
      },
      "source": [
        "## Calculating the envelope of sound"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fb6d13vh5Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the raw data first\n",
        "audio.plot(figsize=(10, 5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbrUpeEKiCFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rectify the audio signal\n",
        "audio_rectified = audio.apply(np.abs)\n",
        "\n",
        "# Plot the result\n",
        "audio_rectified.plot(figsize=(10, 5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYSa96xiHvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Smooth by applying a rolling mean\n",
        "audio_rectified_smooth = audio_rectified.rolling(50).mean()\n",
        "\n",
        "# Plot the result\n",
        "audio_rectified_smooth.plot(figsize=(10, 5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw7BNqDAiLiE",
        "colab_type": "text"
      },
      "source": [
        "## Calculating features from the envelope"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVFT7-PpiL6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate stats\n",
        "means = np.mean(audio_rectified_smooth, axis=0)\n",
        "stds = np.std(audio_rectified_smooth, axis=0)\n",
        "maxs = np.max(audio_rectified_smooth, axis=0)\n",
        "\n",
        "# Create the X and y arrays\n",
        "X = np.column_stack([means, stds, maxs])\n",
        "y = labels.reshape([-1, 1])\n",
        "\n",
        "# Fit the model and score on testing data\n",
        "from sklearn.model_selection import cross_val_score\n",
        "percent_score = cross_val_score(model, X, y, cv=5)\n",
        "print(np.mean(percent_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udb6ZZT1icCc",
        "colab_type": "text"
      },
      "source": [
        "## Derivative features: The tempogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7aWgjSAicZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the tempo of the sounds\n",
        "tempos = []\n",
        "for col, i_audio in audio.items():\n",
        "    tempos.append(lr.beat.tempo(i_audio.values, sr=sfreq, hop_length=2**6, aggregate=None))\n",
        "\n",
        "# Convert the list to an array so you can manipulate it more easily\n",
        "tempos = np.array(tempos)\n",
        "\n",
        "# Calculate statistics of each tempo\n",
        "tempos_mean = tempos.mean(axis=-1)\n",
        "tempos_std = tempos.std(axis=-1)\n",
        "tempos_max = tempos.max(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnMyVsy5jNWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the X and y arrays\n",
        "X = np.column_stack([means, stds, maxs, tempos_mean, tempos_std, tempos_max])\n",
        "y = labels.reshape([-1, 1])\n",
        "\n",
        "# Fit the model and score on testing data\n",
        "percent_score = cross_val_score(model, X, y, cv=5)\n",
        "print(np.mean(percent_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp96qPVxkZeG",
        "colab_type": "text"
      },
      "source": [
        "## Spectrograms of heartbeat audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G3fWXuKkZ2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the stft function\n",
        "from librosa.core import stft\n",
        "\n",
        "# Prepare the STFT\n",
        "HOP_LENGTH = 2**4\n",
        "spec = stft(audio, hop_length=HOP_LENGTH, n_fft=2**7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vIu28gKk3nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from librosa.core import amplitude_to_db\n",
        "from librosa.display import specshow\n",
        "\n",
        "# Convert into decibels\n",
        "spec_db = amplitude_to_db(spec)\n",
        "\n",
        "# Compare the raw audio to the spectrogram of the audio\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
        "axs[0].plot(time, audio)\n",
        "specshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AddUolXzk_em",
        "colab_type": "text"
      },
      "source": [
        "## Engineering spectral features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yjn9ldlk_2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa as lr\n",
        "\n",
        "# Calculate the spectral centroid and bandwidth for the spectrogram\n",
        "bandwidths = lr.feature.spectral_bandwidth(S=spec)[0]\n",
        "centroids = lr.feature.spectral_centroid(S=spec)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzOJdPlCldS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from librosa.core import amplitude_to_db\n",
        "from librosa.display import specshow\n",
        "\n",
        "# Convert spectrogram to decibels for visualization\n",
        "spec_db = amplitude_to_db(spec)\n",
        "\n",
        "# Display these features on top of the spectrogram\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax = specshow(spec_db, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)\n",
        "ax.plot(times_spec, centroids)\n",
        "ax.fill_between(times_spec, centroids - bandwidths / 2, centroids + bandwidths / 2, alpha=.5)\n",
        "ax.set(ylim=[None, 6000])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyLjB1iHliy-",
        "colab_type": "text"
      },
      "source": [
        "## Combining many features in a classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3OW8mE8ljKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop through each spectrogram\n",
        "bandwidths = []\n",
        "centroids = []\n",
        "\n",
        "for spec in spectrograms:\n",
        "    # Calculate the mean spectral bandwidth\n",
        "    this_mean_bandwidth = np.mean(lr.feature.spectral_bandwidth(S=spec))\n",
        "    # Calculate the mean spectral centroid\n",
        "    this_mean_centroid = np.mean(lr.feature.spectral_centroid(S=spec))\n",
        "    # Collect the values\n",
        "    bandwidths.append(this_mean_bandwidth)  \n",
        "    centroids.append(this_mean_centroid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdrsdvHDl72W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create X and y arrays\n",
        "X = np.column_stack([means, stds, maxs, tempo_mean, tempo_max, tempo_std, bandwidths, centroids])\n",
        "y = labels.reshape([-1, 1])\n",
        "\n",
        "# Fit the model and score on testing data\n",
        "percent_score = cross_val_score(model, X, y, cv=5)\n",
        "print(np.mean(percent_score))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}