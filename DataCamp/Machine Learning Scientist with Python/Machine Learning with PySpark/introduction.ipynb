{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "introduction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M39gQeAJzzCs",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_nuuNH0yLNr",
        "colab_type": "text"
      },
      "source": [
        "## Characteristics of Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIdSaHx5zxUi",
        "colab_type": "text"
      },
      "source": [
        "D. All of the above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTH2At4Pz4Dr",
        "colab_type": "text"
      },
      "source": [
        "## Components in a Spark Cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQPV0jhYz6FR",
        "colab_type": "text"
      },
      "source": [
        "C. A load balancer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4qDLV5l0A3j",
        "colab_type": "text"
      },
      "source": [
        "## Location of Spark master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwfPpI6A04R1",
        "colab_type": "text"
      },
      "source": [
        "C. spark://18.188.22.23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooDWT9xo08GQ",
        "colab_type": "text"
      },
      "source": [
        "## Creating a SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlr-2xqj09zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the PySpark module\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession object\n",
        "spark = SparkSession.builder \\\n",
        "                    .master('local[*]') \\\n",
        "                    .appName('test') \\\n",
        "                    .getOrCreate()\n",
        "\n",
        "# What version of Spark?\n",
        "print(spark.version)\n",
        "\n",
        "# Terminate the cluster\n",
        "spark.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXRJ9zdi3O6o",
        "colab_type": "text"
      },
      "source": [
        "## Loading flights data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqmW_JMx3PTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read data from CSV file\n",
        "flights = spark.read.csv('flights.csv',\n",
        "                         sep=',',\n",
        "                         header=True,\n",
        "                         inferSchema=True,\n",
        "                         nullValue='NA')\n",
        "\n",
        "# Get number of records\n",
        "print(\"The data contain %d records.\" % flights.count())\n",
        "\n",
        "# View the first five records\n",
        "flights.show(5)\n",
        "\n",
        "# Check column data types\n",
        "flights.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YD9mMzK4gqX",
        "colab_type": "text"
      },
      "source": [
        "## Loading SMS spam data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWjfrqJt4g8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "# Specify column names and types\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType()),\n",
        "    StructField(\"text\", StringType()),\n",
        "    StructField(\"label\", IntegerType())\n",
        "])\n",
        "\n",
        "# Load data from a delimited file\n",
        "sms = spark.read.csv(\"sms.csv\", sep=';', header=False, schema=schema)\n",
        "\n",
        "# Print schema of DataFrame\n",
        "sms.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}