{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensembles_pipelines.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KW0wjOwfzW6",
        "colab_type": "text"
      },
      "source": [
        "# Ensembles & Pipelines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wDKqXefuP8",
        "colab_type": "text"
      },
      "source": [
        "## Flight duration model: Pipeline stages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnhrH3LCfwkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert categorical strings to index values\n",
        "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
        "\n",
        "# One-hot encode index values\n",
        "onehot = OneHotEncoderEstimator(\n",
        "    inputCols=['org_idx', 'dow'],\n",
        "    outputCols=['org_dummy', 'dow_dummy']\n",
        ")\n",
        "\n",
        "# Assemble predictors into a single column\n",
        "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
        "\n",
        "# A linear regression object\n",
        "regression = LinearRegression(labelCol='duration')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-9hvFU_gPyq",
        "colab_type": "text"
      },
      "source": [
        "## Flight duration model: Pipeline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwljSqrkgQJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import class for creating a pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Construct a pipeline\n",
        "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
        "\n",
        "# Train the pipeline on the training data\n",
        "pipeline = pipeline.fit(flights_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = pipeline.transform(flights_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BywvpG5ygVk-",
        "colab_type": "text"
      },
      "source": [
        "## SMS spam pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqb5Av3qgWC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "\n",
        "# Break text into tokens at non-word characters\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
        "\n",
        "# Remove stop words\n",
        "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
        "\n",
        "# Apply the hashing trick and transform to TF-IDF\n",
        "hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\")\n",
        "idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n",
        "\n",
        "# Create a logistic regression object and add everything to a pipeline\n",
        "logistic = LogisticRegression()\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL5l-zH8g5aW",
        "colab_type": "text"
      },
      "source": [
        "## Cross validating simple flight duration model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg5szEiqg5yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an empty parameter grid\n",
        "params = ParamGridBuilder().build()\n",
        "\n",
        "# Create objects for building and evaluating a regression model\n",
        "regression = LinearRegression(labelCol='duration')\n",
        "evaluator = RegressionEvaluator(labelCol='duration')\n",
        "\n",
        "# Create a cross validator\n",
        "cv = CrossValidator(estimator=regression, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)\n",
        "\n",
        "# Train and test model on multiple folds of the training data\n",
        "cv = cv.fit(flights_train)\n",
        "\n",
        "# NOTE: Since cross-validation builds multiple models, the fit() method can take a little while to complete."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW26jAJMhBMm",
        "colab_type": "text"
      },
      "source": [
        "## Cross validating flight duration model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LK20ajdhBn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an indexer for the org field\n",
        "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
        "\n",
        "# Create an one-hot encoder for the indexed org field\n",
        "onehot = OneHotEncoderEstimator(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
        "\n",
        "# Assemble the km and one-hot encoded fields\n",
        "assembler = VectorAssembler(inputCols=['km', 'org_dummy'], outputCol='features')\n",
        "\n",
        "# Create a pipeline and cross-validator.\n",
        "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
        "cv = CrossValidator(estimator=pipeline,\n",
        "                    estimatorParamMaps=params,\n",
        "                    evaluator=evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VWgp4a_hKxF",
        "colab_type": "text"
      },
      "source": [
        "## Optimizing flights linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHeJAYFEhLJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create parameter grid\n",
        "params = ParamGridBuilder()\n",
        "\n",
        "# Add grids for two parameters\n",
        "params = params.addGrid(regression.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
        "               .addGrid(regression.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "\n",
        "# Build the parameter grid\n",
        "params = params.build()\n",
        "print('Number of models to be tested: ', len(params))\n",
        "\n",
        "# Create cross-validator\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xKgqkrRhOK0",
        "colab_type": "text"
      },
      "source": [
        "## Dissecting the best flight duration model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8FiAK4mhOhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the best model from cross validation\n",
        "best_model = cv.bestModel\n",
        "\n",
        "# Look at the stages in the best model\n",
        "print(best_model.stages)\n",
        "\n",
        "# Get the parameters for the LinearRegression object in the best model\n",
        "best_model.stages[3].extractParamMap()\n",
        "\n",
        "# Generate predictions on testing data using the best model then calculate RMSE\n",
        "predictions = best_model.transform(flights_test)\n",
        "evaluator.evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNTG_EMPhV1k",
        "colab_type": "text"
      },
      "source": [
        "## SMS spam optimised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2UszFIChWPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create parameter grid\n",
        "params = ParamGridBuilder()\n",
        "\n",
        "# Add grid for hashing trick parameters\n",
        "params = params.addGrid(hasher.numFeatures, [1024, 4096, 16384]) \\\n",
        "               .addGrid(hasher.binary, [True, False])\n",
        "\n",
        "# Add grid for logistic regression parameters\n",
        "params = params.addGrid(logistic.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
        "               .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "\n",
        "# Build parameter grid\n",
        "params = params.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auG7JdcNhby0",
        "colab_type": "text"
      },
      "source": [
        "## How many models for grid search?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdawTmRLhcJl",
        "colab_type": "text"
      },
      "source": [
        "D. 360"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQTcXYqthoMU",
        "colab_type": "text"
      },
      "source": [
        "## Delayed flights with Gradient-Boosted Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DY8wVjMhkP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the classes required\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Create model objects and train on training data\n",
        "tree = DecisionTreeClassifier().fit(flights_train)\n",
        "gbt = GBTClassifier().fit(flights_train)\n",
        "\n",
        "# Compare AUC on testing data\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "evaluator.evaluate(tree.transform(flights_test))\n",
        "evaluator.evaluate(gbt.transform(flights_test))\n",
        "\n",
        "# Find the number of trees and the relative importance of features\n",
        "print(gbt.getNumTrees)\n",
        "print(gbt.featureImportances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_Mg8H7Oh1rr",
        "colab_type": "text"
      },
      "source": [
        "## Delayed flights with a Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acU7Dr_rh2Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a random forest classifier\n",
        "forest = RandomForestClassifier()\n",
        "\n",
        "# Create a parameter grid\n",
        "params = ParamGridBuilder() \\\n",
        "            .addGrid(forest.featureSubsetStrategy, ['all', 'onethird', 'sqrt', 'log2']) \\\n",
        "            .addGrid(forest.maxDepth, [2, 5, 10]) \\\n",
        "            .build()\n",
        "\n",
        "# Create a binary classification evaluator\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "\n",
        "# Create a cross-validator\n",
        "cv = CrossValidator(estimator=forest, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqKhJMejh6jb",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRWjbifkh680",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Average AUC for each parameter combination in grid\n",
        "avg_auc = cv.avgMetrics\n",
        "\n",
        "# Average AUC for the best model\n",
        "best_model_auc = max(cv.avgMetrics)\n",
        "\n",
        "# What's the optimal parameter value?\n",
        "opt_max_depth = cv.bestModel.explainParam('maxDepth')\n",
        "opt_feat_substrat = cv.bestModel.explainParam('featureSubsetStrategy')\n",
        "\n",
        "# AUC for best model on testing data\n",
        "best_auc = evaluator.evaluate(cv.transform(flights_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}