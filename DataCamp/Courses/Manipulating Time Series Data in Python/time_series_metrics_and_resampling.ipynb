{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "time_series_metrics_and_resampling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCjZWpssEL4X",
        "colab_type": "text"
      },
      "source": [
        "# Basic Time Series Metrics & Resampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwXbyNi7DGd_",
        "colab_type": "text"
      },
      "source": [
        "## Compare the performance of several asset classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE2maFnwEJ2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import data here\n",
        "prices = pd.read_csv('asset_classes.csv', parse_dates=['DATE'], index_col='DATE')\n",
        "\n",
        "# Inspect prices here\n",
        "print(prices.info())\n",
        "\n",
        "# Select first prices\n",
        "first_prices = prices.iloc[0]\n",
        "\n",
        "# Create normalized\n",
        "normalized = prices.div(first_prices).mul(100)\n",
        "\n",
        "# Plot normalized\n",
        "normalized.plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjGqu_-bE9H0",
        "colab_type": "text"
      },
      "source": [
        "## Comparing stock prices with a benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysXyJMSVE9dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import stock prices and index here\n",
        "stocks = pd.read_csv('nyse.csv', parse_dates=['date'], index_col='date')\n",
        "dow_jones = pd.read_csv('dow_jones.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "# Concatenate data and inspect result here\n",
        "data = pd.concat([stocks, dow_jones], axis=1)\n",
        "print(data.info())\n",
        "\n",
        "# Normalize and plot your data here\n",
        "data.div(data.iloc[0]).mul(100).plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DmhRazkGBgA",
        "colab_type": "text"
      },
      "source": [
        "## Plot performance difference vs benchmark index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiSpHN3xGB1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create tickers\n",
        "tickers = ['MSFT', 'AAPL']\n",
        "\n",
        "# Import stock data here\n",
        "stocks = pd.read_csv('msft_aapl.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "# Import index here\n",
        "sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "# Concatenate stocks and index here\n",
        "data = pd.concat([stocks, sp500], axis=1).dropna()\n",
        "\n",
        "# Normalize data\n",
        "normalized = data.div(data.iloc[0]).mul(100)\n",
        "\n",
        "# Subtract the normalized index from the normalized stock prices, and plot the result\n",
        "normalized[tickers].sub(normalized['SP500'], axis=0).plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILDfpB81ImIc",
        "colab_type": "text"
      },
      "source": [
        "## Convert monthly to weekly data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odsC0peUImeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set start and end dates\n",
        "start = '2016-1-1'\n",
        "end = '2016-2-29'\n",
        "\n",
        "# Create monthly_dates here\n",
        "monthly_dates = pd.date_range(start=start, end=end, freq='M')\n",
        "\n",
        "# Create and print monthly here\n",
        "monthly = pd.Series([1, 2], index=monthly_dates)\n",
        "print(monthly)\n",
        "\n",
        "# Create weekly_dates here\n",
        "weekly_dates = pd.date_range(start=start, end=end, freq='W')\n",
        "\n",
        "# Print monthly, reindexed using weekly_dates\n",
        "print(monthly.reindex(weekly_dates))\n",
        "print(monthly.reindex(weekly_dates, method='bfill'))\n",
        "print(monthly.reindex(weekly_dates, method='ffill'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlqA76IXJpKR",
        "colab_type": "text"
      },
      "source": [
        "## Create weekly from monthly unemployment data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RBhcePXJpfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import data here\n",
        "data = pd.read_csv('unemployment.csv', parse_dates=['date'], index_col='date')\n",
        "\n",
        "# Show first five rows of weekly series\n",
        "print(data.asfreq('W').head())\n",
        "\n",
        "# Show first five rows of weekly series with bfill option\n",
        "print(data.asfreq('W', method='bfill').head())\n",
        "\n",
        "# Create weekly series with ffill option and show first five rows\n",
        "weekly_ffill = data.asfreq('W', method='ffill')\n",
        "print(weekly_ffill.head())\n",
        "\n",
        "# Plot weekly_fill starting 2015 here \n",
        "weekly_ffill['2015':].plot()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWBDUBHFLr9t",
        "colab_type": "text"
      },
      "source": [
        "## Use interpolation to create weekly employment data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4WoCHXXLsUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect data here\n",
        "print(monthly.info())\n",
        "\n",
        "# Create weekly dates\n",
        "weekly_dates = pd.date_range(monthly.index.min(), monthly.index.max(), freq='W')\n",
        "\n",
        "# Reindex monthly to weekly data\n",
        "weekly = monthly.reindex(weekly_dates)\n",
        "\n",
        "# Create ffill and interpolated columns\n",
        "weekly['ffill'] = weekly['UNRATE'].ffill()\n",
        "weekly['interpolated'] = weekly['UNRATE'].interpolate()\n",
        "\n",
        "# Plot weekly\n",
        "weekly.plot()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-L7wszKMiJb",
        "colab_type": "text"
      },
      "source": [
        "## Interpolate debt/GDP and compare to unemployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk3TX0gIMie2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import & inspect data here\n",
        "data = pd.read_csv('debt_unemployment.csv', parse_dates=['date'], index_col='date')\n",
        "print(data.info())\n",
        "\n",
        "# Interpolate and inspect here\n",
        "interpolated = data.interpolate()\n",
        "print(interpolated.info())\n",
        "\n",
        "# Plot interpolated data here\n",
        "interpolated.plot(secondary_y='Unemployment')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDiklRJ5OPvG",
        "colab_type": "text"
      },
      "source": [
        "## Compare weekly, monthly and annual ozone trends for NYC & LA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfgFruqFOQEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import and inspect data here\n",
        "ozone = pd.read_csv('ozone.csv', parse_dates=['date'], index_col='date')\n",
        "print(ozone.info())\n",
        "\n",
        "\n",
        "# Calculate and plot the weekly average ozone trend\n",
        "ozone.resample('W').mean().plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate and plot the monthly average ozone trend\n",
        "ozone.resample('M').mean().plot()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Calculate and plot the annual average ozone trend\n",
        "ozone.resample('A').mean().plot()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFA6ZlZgO2Wo",
        "colab_type": "text"
      },
      "source": [
        "## Compare monthly average stock prices for Facebook and Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f5BMdhyO2tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import and inspect data here\n",
        "stocks = pd.read_csv('stocks.csv', parse_dates=['date'], index_col='date')\n",
        "print(stocks.info())\n",
        "\n",
        "# Calculate and plot the monthly averages\n",
        "monthly_average = stocks.resample('M').mean()\n",
        "monthly_average.plot(subplots=True)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc9wXG1sPNff",
        "colab_type": "text"
      },
      "source": [
        "## Compare quarterly GDP growth rate and stock returns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFouxlWnPN10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import and inspect gdp_growth here\n",
        "gdp_growth = pd.read_csv('gdp_growth.csv', parse_dates=['date'], index_col='date')\n",
        "print(gdp_growth.info())\n",
        "\n",
        "# Import and inspect djia here\n",
        "djia = pd.read_csv('djia.csv', parse_dates=['date'], index_col='date')\n",
        "print(djia.info())\n",
        "\n",
        "# Calculate djia quarterly returns here \n",
        "djia_quarterly = djia.resample('QS').first()\n",
        "djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
        "\n",
        "# Concatenate, rename and plot djia_quarterly_return and gdp_growth here \n",
        "data = pd.concat([gdp_growth, djia_quarterly_return], axis=1)\n",
        "data.columns = ['gdp', 'djia']\n",
        "\n",
        "data.plot()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZU0tLqjQWKp",
        "colab_type": "text"
      },
      "source": [
        "## Visualize monthly mean, median and standard deviation of S&P500 returns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHc1Y-WAQW3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import data here\n",
        "sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n",
        "print(sp500.info())\n",
        "\n",
        "# Calculate daily returns here\n",
        "daily_returns = sp500.squeeze().pct_change()\n",
        "\n",
        "# Resample and calculate statistics\n",
        "stats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n",
        "\n",
        "# Plot stats here\n",
        "stats.plot()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}